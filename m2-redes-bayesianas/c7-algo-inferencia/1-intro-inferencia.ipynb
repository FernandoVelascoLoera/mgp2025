{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a inferencia\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://static.thenounproject.com/png/542457-200.png\" width=\"300px\" height=\"300px\" />\n",
    "\n",
    "> Hasta ahora hemos hablado de la representación y propiedades básicas de las Redes Bayesianas, y como a través de su estructura podemos codificar ciertas independencias.\n",
    ">\n",
    "> En esta serie de clases operacionalizaremos las redes Bayesianas y estudiaremos como usar dichas representaciones (modelos) para responder preguntas que podrían surgir de la situación que estamos modelando.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Entender los diferentes tipos de preguntas que le podemos hacer a un modelo gráfico.\n",
    "\n",
    "> **Referencias:**\n",
    "> - Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Ch. 9.\n",
    "> - Pattern Recognition and Machine Learning, by Christopher M. Bishop - Cap. 8.\n",
    "> - Bayesian Reasoning and Machine Learning by David Barber. Cap. 5.\n",
    "\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://static.thenounproject.com/png/542457-200.png.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "En la clase anterior comenzamos nuestro estudio de redes Bayesianas, y vimos como las probabilidades (nuestras creencias) acerca de una variable cambian cuando incorporamos evidencia, de una manera intuitiva.\n",
    "\n",
    "En esta secuencia, describiremos algunos algoritmos para calcular eficientemente estas probabilidades, cuando la evidencia cambia. Similarmente, veremos como usar algoritmos de inferencia para hacer predicciones de los valores de variables basados en nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Probabilidades condicionales\n",
    "\n",
    "Son el tipo de pregunta más común que le hacemos a un modelo probabilístico.\n",
    "\n",
    "Dadas:\n",
    "\n",
    "- Una distribución conjunta de probabilidad\n",
    "\n",
    "  $$P(X_1,\\dots, X_n),$$\n",
    "\n",
    "  (modelada a través de una red Bayesiana);\n",
    "  \n",
    "- Un conjunto de variables de interés $\\bar{Y}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$;\n",
    "\n",
    "- Un conjunto de variables observadas (evidencia) $\\bar{E} = \\bar{e}$, con $\\bar{E}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$,\n",
    "\n",
    "Definimos $\\bar{W} = \\left\\{X_1,\\dots, X_n\\right\\} \\setminus \\left\\{\\bar{Y} \\cup \\bar{E}\\right\\}$ como el resto de variables.\n",
    "\n",
    "**La tarea es calcular la probabilidad condicional:** $P(\\bar{Y} | \\bar{E}=\\bar{e})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicaciones:**\n",
    "\n",
    "- *Un modelo de riesgo crediticio*: se observan ciertas variables del cliente (flujo de capital, patrimonio, activos, pasivos, historial ...), y se estaría interesado en calcular la probabilidad de ciertas variables no obervables para el banco.\n",
    "\n",
    "- *Un sistema de diagnóstico médico*: se observan ciertas variables (síntomas, resultados de exámenes) y estamos interesados en calcular la probabilidad de presencia de alguna enfermedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo?**\n",
    "\n",
    "Por la definición de probabilidad condicional:\n",
    "\n",
    "$$P(\\bar{Y} | \\bar{E}=\\bar{e}) = \\frac{P(\\bar{Y}, \\bar{e})}{P(\\bar{e})}.$$\n",
    "\n",
    "En esta expresión:\n",
    "\n",
    "- $P(\\bar{Y}, \\bar{e}) = \\sum_{\\bar{W}} P(\\bar{Y}, \\bar{e}, \\bar{W})$.\n",
    "\n",
    "  Recordemos que $\\left\\{X_1,\\dots, X_n\\right\\} = \\bar{Y} \\cup \\bar{E} \\cup \\bar{W}$. Entonces, los términos en la suma del lado derecho son probabilidades conjuntas de todas las variables.\n",
    "  \n",
    "- $P(\\bar{e}) = \\sum_{\\bar{Y}} P(\\bar{Y}, \\bar{e})$.\n",
    "\n",
    "  Esta es simplemente una constante de normalización para convertir $P(\\bar{Y}, \\bar{e})$ into $P(\\bar{Y} | \\bar{e})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, en principio podríamos:\n",
    "\n",
    "- Tomar una red Bayesiana;\n",
    "- Multiplicar todas las probabilidades condicionales para obtener la distribución condicional;\n",
    "- Marginalizar las variables no deseadas en la distribución conjunta;\n",
    "- **¡Listo!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** Restaurante\n",
    "\n",
    "Variables:\n",
    "- Ubicación $L$ (Bad: $l^0$, Good: $l^1$).\n",
    "- Calidad $Q$ (Bad: $q^0$, Normal: $q^1$, Good: $q^2$).\n",
    "- Costo $C$ (Low: $c^0$, High: $c^1$).\n",
    "- Número de personas $N$ (Low: $n^0$, High: $n^1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/restaurant.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.factors.discrete.TabularCPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuál es el problema?**\n",
    "\n",
    "*El problema crece exponencialmente en complejidad computacional con el número de variables / cardinalidad*.\n",
    "\n",
    "En efecto, el problema de inferencia en redes Bayesianas (tal como la mayoría de problemas interesantes en matemáticas) es $\\mathcal{NP}-$hard. \n",
    "\n",
    "**¿Esto qué significa?**\n",
    "\n",
    "- Si un problmea es $\\mathcal{NP}-$hard es muy poco probable de que encontremos una solución general eficiente.\n",
    "\n",
    "- Esto significa que **todos los algoritmos** que se han construido hasta hoy, requieren un tiempo (o número de operaciones básicas) exponencial en el tamaño de la representación del problema.\n",
    "\n",
    "- Estos resultados son, claramente, un análisis del peor caso. Estudiaremos ciertos algoritmos (exactos y aproximados) que nos permitirán hacerlo mucho mejor que este peor caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inferencia Máximo A-Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadas:\n",
    "\n",
    "- Una distribución conjunta de probabilidad\n",
    "\n",
    "  $$P(X_1,\\dots, X_n),$$\n",
    "\n",
    "  (modelada a través de una red Bayesiana);\n",
    "  \n",
    "- Un conjunto de variables de interés $\\bar{Y}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$;\n",
    "\n",
    "- Un conjunto de variables observadas (evidencia) $\\bar{E} = \\bar{e}$, con $\\bar{E}\\subseteq \\left\\{X_1,\\dots, X_n\\right\\}$,\n",
    "\n",
    "Supondremos en este caso, por simplicidad, que $\\bar{Y}\\cup \\bar{E} = \\left\\{X_1,\\dots, X_n\\right\\}$.\n",
    "\n",
    "**La tarea es calcular:** \n",
    "\n",
    "$$MAP(\\bar{Y} | \\bar{E}=\\bar{e}) = \\arg\\max_{\\bar{y}\\in\\mathrm{Val}(\\bar{Y})} P(\\bar{Y} | \\bar{E}=\\bar{e}).$$\n",
    "\n",
    "> ¡Podría haber múltiples soluciones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicación:**\n",
    "\n",
    "- Clasificador: una vez aprendemos una modelo a partir de datos / experiencia, podríamos querer calcular cuál es el valor más probable de ciertas variables, dada la observación de otras variables (evidencia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAP $\\neq$ Máx. sobre marginales:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/simple.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, este problema es $\\mathcal{NP}-$hard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
